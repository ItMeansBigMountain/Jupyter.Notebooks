{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making an AI if tumors are Malignant or Benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data set\n",
    "dataset = pd.read_csv(\"cancer.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have AI map correlations of deadly vs non deadly cancers\n",
    "\n",
    "x = all atrributes of the diagnosis\n",
    "\n",
    "y = diagnosis (deadly or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop specified columns, variable equals all else\n",
    "x = dataset.drop( columns =  [\"diagnosis(1=m, 0=b)\"]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing specified column in data set\n",
    "y = dataset[\"diagnosis(1=m, 0=b)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We need to split the data set into two halfs...\n",
    "first half will be training data\n",
    "\n",
    "second half will be testing data (did the ai do its job correctly?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split( x  , y  , test_size = 0.2  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural Netowork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created neural network data model\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# adding layers to the neural network\n",
    "model.add( tf.keras.layers.Dense(256 , input_shape = [None, x_train.shape[0], x_train.shape[1]] , activation = 'sigmoid'  )   )\n",
    "model.add( tf.keras.layers.Dense(256 , activation = 'sigmoid'  )   )\n",
    "model.add( tf.keras.layers.Dense(1 , activation = 'sigmoid'  )   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile our model\n",
    "model.compile( optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING DATA MODEL\n",
    "model.fit( x_train , y_train , epochs = 1000 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING DATA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate( x_test , y_test )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b2762b5f3fa64b4bddd7b815ada8e289236e6457979796da29c66f5658721800"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
